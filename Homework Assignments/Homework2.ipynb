{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #2\n",
    "\n",
    "## CNNs Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1\n",
    "a. You have an input volume that is 15x15x8 and pad it using *p = 2*. What is the dimension of the resulting volume?\n",
    "\n",
    "b. You have an input volume that is 32x32x16 and apply max pooling with a stride of 2 and a filter of size of 2x2. What is the output volume?\n",
    "\n",
    "c. You have an input volume that is 63x63x16 and convolve it with 32 filters that are each 7x7x16, and a stride of 1. You want to use a \"same\" convolution. What is the padding *p*?\n",
    "\n",
    "d. You have an input volume that is 63x63x16 and convolve it with 32 filters that are each 7x7x16, using a stride of 2 and no padding. What is the output volume?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIH Chest X-ray Dataset Sample\n",
    "Chest X-ray exams are one of the most frequent and cost-effective medical imaging examinations available. However, clinical diagnosis of a chest X-ray can be challenging and sometimes more difficult than diagnosis via chest CT imaging. The lack of large publicly available datasets with annotations means it is still very difficult, if not impossible, to achieve clinically relevant computer-aided detection and diagnosis (CAD) in real world medical sites with chest X-rays. One major hurdle in creating large X-ray image datasets is the lack resources for labeling so many images. Prior to the release of this dataset, Openi was the largest publicly available source of chest X-ray images with 4,143 images available.\n",
    "\n",
    "The NIH Chest X-ray Dataset is comprised of 112,120 X-ray images with disease labels from 30,805 unique patients. To create these labels, the authors used Natural Language Processing to text-mine disease classifications from the associated radiological reports. The labels are expected to be >90% accurate and suitable for weakly-supervised learning. The original radiology reports are not publicly available but you can find more details on the labeling process in this Open Access paper: \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases.\" (Wang et al.)\n",
    "\n",
    "There are several labels that described the findings of the x-rays. For our purposes, I have made this a binary classification task and re-labeled the images as either **Infiltration** or **Not Infiltration**. A pulmonary infiltrate is a substance denser than air, such as pus, blood, or protein, which lingers within the parenchyma of the lungs. Pulmonary infiltrates are associated with pneumonia, tuberculosis, and nocardiosis.\n",
    "\n",
    "The data are contained in a folder named **xray-small** and you can access it in Module 4 on the [course Canvas site](https://canvas.harvard.edu/courses/34618/pages/week-4). There are 950 Infiltration images, and 950 Not Infiltration images that are labeled **\"Infiltration_1.png\" - \"Infiltration_950.png\"** and **\"Not_Infiltration_1.png\" - \"Not_Infiltration_950.png\"**. The images have been split into 6 different folders. The first 500 infiltration and not infiltration images are contained in the **train_dir**, the next 225 infiltration images and not infiltration images are contained in **validation_dir**, and the last 225 infiltration images and not infiltration images are contained in the **test_dir**. If you are working in JupyterHub on Canvas, you need to first download the data and then upload the data to JupyterHub. If you are working on your own installation of Jupyter notebook, download the data to your machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Needed packages\n",
    "import keras\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2\n",
    "Build your CNN. Do **not** simply copy the one from the example Jupyter notebook. Come up with your own number of layers, filters, filter sizes, padding (if any), strides (if more than 1), etc. You will be inputting images of shape `150x150x3`. Be sure to include dense layers and an appropriate output layer, activation functions, loss function, optimization algorithm and performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #3\n",
    "Format your data appropriately to be fed into your network. Be sure to use the `ImageDataGenerator` utility in Keras and to scale the data correctly and resize the images to be `150x150x3`. Set `batch_size=25`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #4. \n",
    "Fit the model using a batch generator. Set `epochs = 30` and `validation_steps = 18`. Be sure to choose the correct `steps_per_epoch`. Depending on the size of your network, this may take some time - most likely around an hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #5\n",
    "Plot the training and validation accuracy as well as the training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #6\n",
    "We are using a relatively small sample size to train our CNN. Perform data augmentation to generate more training examples and then train your model again from scratch. Plot the training and validation accuracy as well as the training and validation loss. Comment on the differences between these plots and those generated in question #5. You may add a dropout layer if you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #7.\n",
    "Now you will use a pretrained network as a convolutional base. Choose one of the image-classification pretrained networks available in Keras (Xception, Inception V3, ResNet50, VGG16, VGG19, MobileNet), and set `weights = 'imagenet'`. Run the command `conv_base.summary()` and report the number of parameters the pretrained network has learned. \n",
    "\n",
    "Build a new network using the pretrained network as a base. Do **not** unfreeze any of the layers of the base. Use the base to extract features only. Remeber to use appropriate dense layers after using the base to extract features, including an appropriate output layer. Keep `epochs = 30`. This should take about 30-45 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8.\n",
    "Plot the training and validation loss as well as the training and validation accuracy and comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9.\n",
    "Read the article that presented the pretrained model you chose and write a summary. Include comments on the architecture and usefulness of the network. Your summary should be between 250 - 500 words. \n",
    "\n",
    "Type your summary here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #10.\n",
    "Describe your favorite part of Mohammad's guest lecture. Come up with an example of how to use the methods he discussed. \n",
    "\n",
    "Type your response here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
